{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Tools\n",
    "\n",
    "Lots of libraries exist that will do sentiment analysis for you. Imagine that: just taking a sentence, throwing it into a library, and geting back a score! How convenient!\n",
    "\n",
    "It also might be **totally irresponsible** unless you know how the sentiment analyzer was built. In this section we're going to see how sentiment analysis is done with a few different packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Use `pip install` two language processing packages, NLTK and Textblob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\savey\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.7.6-cp39-cp39-win_amd64.whl (270 kB)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: click in c:\\users\\savey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\savey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: tqdm, regex, joblib, nltk, textblob\n",
      "Successfully installed joblib-1.0.1 nltk-3.6.2 regex-2021.7.6 textblob-0.15.3 tqdm-4.61.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install nltk textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "### NLTK: Natural Language Tooklit\n",
    "\n",
    "[Natural Language Toolkit](https://www.nltk.org/) is the basis for a lot of text analysis done in Python. It's old and terrible and slow, but it's just been used for so long and does so many things that it's generally the default when people get into text analysis. The new kid on the block is [spaCy](https://spacy.io/), but it doesn't do sentiment analysis out of the box so we're leaving it out of this right now.\n",
    "\n",
    "When you first run NLTK, you need to download some datasets to make sure it will be able to do everything you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\savey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\savey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\savey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do sentiment analysis with NLTK, it only takes a couple lines of code. To determine sentiment, it's using a tool called **VADER**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.153, 'neu': 0.688, 'pos': 0.159, 'compound': 0.0276}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "sia.polarity_scores(\"This restaurant was great, but I'm not sure if I'll go there again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking `SentimentIntensityAnalyzer` for the `polarity_score` gave us four values in a dictionary:\n",
    "\n",
    "- **negative:** the negative sentiment in a sentence\n",
    "- **neutral:** the neutral sentiment in a sentence\n",
    "- **positive:** the postivie sentiment in the sentence\n",
    "- **compound:** the aggregated sentiment. \n",
    "    \n",
    "Seems simple enough!\n",
    "\n",
    "### Use NLTK/VADER to determine the sentiment of the following sentences:\n",
    "\n",
    "* I just got a call from my boss - does he realise it's Saturday?\n",
    "* I just got a call from my boss - does he realise it's Saturday? :)\n",
    "* I just got a call from my boss - does he realise it's Saturday? ðŸ˜Š\n",
    "\n",
    "Do the results seem reasonable? What does VADER do with emoji and emoticons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"I just got a call from my boss - does he realise it's Saturday?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.786, 'pos': 0.214, 'compound': 0.4588}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"I just got a call from my boss - does he realise it's Saturday? :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"I just got a call from my boss - does he realise it's Saturday? ðŸ˜Š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think it doesn't understand the emoji the same way it understood the emoticon?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_I'm guessing that because NLTK is older, it was made before the widespread usage of emojis in English._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When VADER was a baby\n",
    "\n",
    "As we talked about in class, knowing the dataset a language model was trained on can be pretty important!\n",
    "\n",
    "[Can you uncover how VADER was trained by reading its homepage?](https://github.com/cjhutto/vaderSentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_It looks like they created a lexicon that was validated by 10 independent human judges who rated over 9000 tokens (words, phrases, etc.) on a scale from -4 (very negative) to 4 (very positive), with 0 being neutral. They also used tweets, snippets from the New York Times editorial page, movie reviews from Rotten Tomatoes, and customer reviews on Amazon._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob\n",
    "\n",
    "TextBlob is built on top of NLTK, but is infinitely easier to use. It's still slow, but _it's so so so easy to use_. \n",
    "\n",
    "You can just feed TextBlob your sentence, then ask for a `.sentiment`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.275, subjectivity=0.8194444444444444)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"This restaurant was great, but I'm not sure if I'll go there again.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How could it possibly be easier than that?!?!?** This time we get a `polarity` and a `subjectivity` instead of all of those different scores, but it's basically the same idea.\n",
    "\n",
    "Try the TextBlob sentiment tool with another sentence of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"This morning I went to work and it was sunny.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.019886363636363633, subjectivity=0.5227272727272727)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"I think it's actually a little positive.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5071428571428571, subjectivity=0.35)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"I want to know what is something that brings you pure joy? For me that's roller skating and dancing.\")\n",
    "\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.35101010101010105, subjectivity=0.5277777777777778)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"Having a bike has cleared up my skin, made me more gay and given me a reason to live tbh\")\n",
    "\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"THIS STORM???!\")\n",
    "\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.3499999999999999, subjectivity=0.5119047619047619)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"iâ€™ve already started unfollowing people for their bad ted lasso takes. i simply do not have the bandwidth\")\n",
    "\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.5, subjectivity=1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"That complicated data visualization youâ€™ve been working on/crying over, you should consider instead making a table.\")\n",
    "\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like options: it turns out TextBlob actually has multiple sentiment analysis tools! How fun! We can plug in a different analyzer to get a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.5879425317005774, p_neg=0.41205746829942275)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobber = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "\n",
    "blob = blobber(\"This restaurant was great, but I'm not sure if I'll go there again.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a **very different result.** To understand why it's so different, we need to talk about where these sentiment numbers come from. You can read about [the library behind TextBlob's opinions about sentiment](https://github.com/clips/pattern/wiki/pattern-en#sentiment) but they don't really go into (easily-accessible) detail about how it happens.\n",
    "\n",
    "But first: try it with one of your own sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.6600172903937133, p_neg=0.3399827096062867)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = blobber(\"Having a bike has cleared up my skin, made me more gay and given me a reason to live tbh\")\n",
    "\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How were they made?\n",
    "\n",
    "The most important thing to understand is **sentiment is always just an opinion.** In this case it's an opinion, yes, but specifically **the opinion of a machine.**\n",
    "\n",
    "### VADER\n",
    "\n",
    "NLTK's Sentiment Intensity Analyzer works is using something called **VADER**, which is a list of words that have a sentiment associated with each of them.\n",
    "\n",
    "|Word|Sentiment rating|\n",
    "|---|---|\n",
    "|tragedy|-3.4|\n",
    "|rejoiced|2.0|\n",
    "|disaster|-3.1|\n",
    "|great|3.1|\n",
    "\n",
    "If you have more positives, the sentence is more positive. If you have more negatives, it's more negative. It can also take into account things like capitalization - you can read more about the classifier [here](http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html), or the actual paper it came out of [here](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf).\n",
    "\n",
    "**How do they know what's positive/negative?** They came up with a very big list of words, then asked people on the internet and paid them one cent for each word they scored.\n",
    "\n",
    "### TextBlob's `.sentiment`\n",
    "\n",
    "TextBlob's sentiment analysis is based on a separate library called [pattern](https://www.clips.uantwerpen.be/pattern).\n",
    "\n",
    "> The sentiment analysis lexicon bundled in Pattern focuses on adjectives. It contains adjectives that occur frequently in customer reviews, hand-tagged with values for polarity and subjectivity.\n",
    "\n",
    "Same kind of thing as NLTK's VADER, but it specifically looks at words from customer reviews.\n",
    "\n",
    "**How do they know what's positive/negative?** They look at (mostly) adjectives that occur in customer reviews and hand-tag them.\n",
    "\n",
    "### TextBlob's `.sentiment` + NaiveBayesAnalyzer\n",
    "\n",
    "TextBlob's other option uses a `NaiveBayesAnalyzer`, which is a machine learning technique. When you use this option with TextBlob, the sentiment is coming from \"an NLTK classifier trained on a movie reviews corpus.\"\n",
    "\n",
    "**How do they know what's positive/negative?** Looked at movie reviews and scores using machine learning, the computer _automatically learned_ what words are associated with a positive or negative rating.\n",
    "\n",
    "## What's this mean for me?\n",
    "\n",
    "When you're doing sentiment analysis with tools like this, you should have a few major questions: \n",
    "\n",
    "* Where kind of dataset does the list of known words come from?\n",
    "* Do they use all the words, or a selection of the words?\n",
    "* Where do the positive/negative scores come from?\n",
    "\n",
    "Let's compare the tools we've used so far.\n",
    "\n",
    "|technique|word source|word selection|scores|\n",
    "|---|---|---|---|\n",
    "|NLTK (VADER)|everywhere|hand-picked|internet people, word-by-word|\n",
    "|TextBlob|product reviews|hand-picked, mostly adjectives|internet people, word-by-word|\n",
    "|TextBlob + NaiveBayesAnalyzer|movie reviews|all words|automatic based on score|\n",
    "\n",
    "A major thing that should jump out at you is **how different the sources are.**\n",
    "\n",
    "While VADER focuses on content found everywhere, TextBlob's two options are specific to certain domains. The [original paper for VADER](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf) passive-aggressively noted that VADER is effective at general use, but being trained on a specific domain can have benefits: \n",
    "\n",
    "> While some algorithms performed decently on test data from the specific domain for which it was expressly trained, they do not significantly outstrip the simple model we use.\n",
    "\n",
    "They're basically saying, \"if you train a model on words from a certain field, it will be good at sentiment in that certain field.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison chart\n",
    "\n",
    "Because they're build differently, sentiment analysis tools don't always agree. Let's take a set of sentences and compare each analyzer's understanding of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love love love love this kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate hate hate hate this keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you see the baseball game yesterday?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The package was delivered late and the contents were broken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trashy television shows are some of my favorites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I find chirping birds irritating, but I know I'm not the only one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    content\n",
       "0                                         I love love love love this kitten\n",
       "1                                       I hate hate hate hate this keyboard\n",
       "2                                       I'm not sure how I feel about toast\n",
       "3                                  Did you see the baseball game yesterday?\n",
       "4               The package was delivered late and the contents were broken\n",
       "5                          Trashy television shows are some of my favorites\n",
       "6  I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\n",
       "7         I find chirping birds irritating, but I know I'm not the only one"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "df = pd.DataFrame({'content': [\n",
    "    \"I love love love love this kitten\",\n",
    "    \"I hate hate hate hate this keyboard\",\n",
    "    \"I'm not sure how I feel about toast\",\n",
    "    \"Did you see the baseball game yesterday?\",\n",
    "    \"The package was delivered late and the contents were broken\",\n",
    "    \"Trashy television shows are some of my favorites\",\n",
    "    \"I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\",\n",
    "    \"I find chirping birds irritating, but I know I'm not the only one\",\n",
    "]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_f5634_row0_col1{\n",
       "            background-color:  #c3e67d;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row0_col2{\n",
       "            background-color:  #fff6b0;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row0_col3{\n",
       "            background-color:  #73c264;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row1_col1{\n",
       "            background-color:  #fa9656;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row1_col2{\n",
       "            background-color:  #feeb9d;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row1_col3{\n",
       "            background-color:  #f67a49;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row2_col1,#T_f5634_row7_col3{\n",
       "            background-color:  #fee797;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row2_col2{\n",
       "            background-color:  #d3ec87;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row2_col3{\n",
       "            background-color:  #fee999;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row3_col1{\n",
       "            background-color:  #fed683;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row3_col2{\n",
       "            background-color:  #b1de71;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row3_col3,#T_f5634_row5_col1{\n",
       "            background-color:  #fffebe;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row4_col1{\n",
       "            background-color:  #fede89;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row4_col2{\n",
       "            background-color:  #fdbd6d;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row4_col3{\n",
       "            background-color:  #feca79;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row5_col2{\n",
       "            background-color:  #fbfdba;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row5_col3{\n",
       "            background-color:  #cfeb85;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row6_col1{\n",
       "            background-color:  #91d068;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row6_col2{\n",
       "            background-color:  #a0d669;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row6_col3{\n",
       "            background-color:  #fdb567;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row7_col1{\n",
       "            background-color:  #feec9f;\n",
       "            color:  #000000;\n",
       "        }#T_f5634_row7_col2{\n",
       "            background-color:  #e3f399;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_f5634_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >content</th>        <th class=\"col_heading level0 col1\" >textblob</th>        <th class=\"col_heading level0 col2\" >textblob_bayes</th>        <th class=\"col_heading level0 col3\" >nltk</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f5634_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f5634_row0_col0\" class=\"data row0 col0\" >I love love love love this kitten</td>\n",
       "                        <td id=\"T_f5634_row0_col1\" class=\"data row0 col1\" >0.500000</td>\n",
       "                        <td id=\"T_f5634_row0_col2\" class=\"data row0 col2\" >-0.087933</td>\n",
       "                        <td id=\"T_f5634_row0_col3\" class=\"data row0 col3\" >0.957100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f5634_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_f5634_row1_col0\" class=\"data row1 col0\" >I hate hate hate hate this keyboard</td>\n",
       "                        <td id=\"T_f5634_row1_col1\" class=\"data row1 col1\" >-0.800000</td>\n",
       "                        <td id=\"T_f5634_row1_col2\" class=\"data row1 col2\" >-0.214151</td>\n",
       "                        <td id=\"T_f5634_row1_col3\" class=\"data row1 col3\" >-0.941300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f5634_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_f5634_row2_col0\" class=\"data row2 col0\" >I'm not sure how I feel about toast</td>\n",
       "                        <td id=\"T_f5634_row2_col1\" class=\"data row2 col1\" >-0.250000</td>\n",
       "                        <td id=\"T_f5634_row2_col2\" class=\"data row2 col2\" >0.394659</td>\n",
       "                        <td id=\"T_f5634_row2_col3\" class=\"data row2 col3\" >-0.241100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f5634_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_f5634_row3_col0\" class=\"data row3 col0\" >Did you see the baseball game yesterday?</td>\n",
       "                        <td id=\"T_f5634_row3_col1\" class=\"data row3 col1\" >-0.400000</td>\n",
       "                        <td id=\"T_f5634_row3_col2\" class=\"data row3 col2\" >0.613050</td>\n",
       "                        <td id=\"T_f5634_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f5634_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_f5634_row4_col0\" class=\"data row4 col0\" >The package was delivered late and the contents were broken</td>\n",
       "                        <td id=\"T_f5634_row4_col1\" class=\"data row4 col1\" >-0.350000</td>\n",
       "                        <td id=\"T_f5634_row4_col2\" class=\"data row4 col2\" >-0.574270</td>\n",
       "                        <td id=\"T_f5634_row4_col3\" class=\"data row4 col3\" >-0.476700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f5634_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_f5634_row5_col0\" class=\"data row5 col0\" >Trashy television shows are some of my favorites</td>\n",
       "                        <td id=\"T_f5634_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
       "                        <td id=\"T_f5634_row5_col2\" class=\"data row5 col2\" >0.040076</td>\n",
       "                        <td id=\"T_f5634_row5_col3\" class=\"data row5 col3\" >0.421500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f5634_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_f5634_row6_col0\" class=\"data row6 col0\" >I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
       "                        <td id=\"T_f5634_row6_col1\" class=\"data row6 col1\" >0.800000</td>\n",
       "                        <td id=\"T_f5634_row6_col2\" class=\"data row6 col2\" >0.717875</td>\n",
       "                        <td id=\"T_f5634_row6_col3\" class=\"data row6 col3\" >-0.629600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f5634_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_f5634_row7_col0\" class=\"data row7 col0\" >I find chirping birds irritating, but I know I'm not the only one</td>\n",
       "                        <td id=\"T_f5634_row7_col1\" class=\"data row7 col1\" >-0.200000</td>\n",
       "                        <td id=\"T_f5634_row7_col2\" class=\"data row7 col2\" >0.257148</td>\n",
       "                        <td id=\"T_f5634_row7_col3\" class=\"data row7 col3\" >-0.250000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2303443cb50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_scores(content):\n",
    "    blob = TextBlob(content)\n",
    "    nb_blob = blobber(content)\n",
    "    sia_scores = sia.polarity_scores(content)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'content': content,\n",
    "        'textblob': blob.sentiment.polarity,\n",
    "        'textblob_bayes': nb_blob.sentiment.p_pos - nb_blob.sentiment.p_neg,\n",
    "        'nltk': sia_scores['compound'],\n",
    "    })\n",
    "\n",
    "scores = df.content.apply(get_scores)\n",
    "scores.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, those really don't agree with one another! Which one do you agree with the most? Did it get everything \"right?\"\n",
    "\n",
    "While it seemed like magic to be able to plug a sentence into a sentiment analyzer and get a result back... maybe things aren't as magical as we thought.\n",
    "\n",
    "#### Try ten sentences of your own\n",
    "\n",
    "Just curious: can you make sentences that specifically \"trick\" one sentiment analysis tool or another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nothing I love more than my boss telling me I have to stay late on Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks, I hate it! :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lol real genius over here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hate love hate love love love hate hate HATE!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haters gonna hate hate hate hate hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can't believe I only have one more day in this beautiful paradise! I don't wanna leave! :(</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      content\n",
       "0                   nothing I love more than my boss telling me I have to stay late on Friday\n",
       "1                                                                       thanks, I hate it! :)\n",
       "2                                                                   lol real genius over here\n",
       "3                                            hate love hate love love love hate hate HATE!!!!\n",
       "4                                                       haters gonna hate hate hate hate hate\n",
       "5  Can't believe I only have one more day in this beautiful paradise! I don't wanna leave! :("
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'content': [\n",
    "    \"nothing I love more than my boss telling me I have to stay late on Friday\",\n",
    "    \"thanks, I hate it! :)\",\n",
    "    \"lol real genius over here\",\n",
    "    \"hate love hate love love love hate hate HATE!!!!\",\n",
    "    \"haters gonna hate hate hate hate hate\",\n",
    "    \"Can't believe I only have one more day in this beautiful paradise! I don't wanna leave! :(\"\n",
    "]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_9da6d_row0_col1{\n",
       "            background-color:  #f7844e;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row0_col2,#T_9da6d_row0_col3,#T_9da6d_row2_col2,#T_9da6d_row3_col1,#T_9da6d_row4_col1,#T_9da6d_row4_col3{\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9da6d_row1_col1{\n",
       "            background-color:  #c21c27;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9da6d_row1_col2{\n",
       "            background-color:  #f88950;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row1_col3{\n",
       "            background-color:  #fdaf62;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row2_col1{\n",
       "            background-color:  #fed481;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row2_col3{\n",
       "            background-color:  #fdc171;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row3_col2{\n",
       "            background-color:  #ef633f;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row3_col3{\n",
       "            background-color:  #feefa3;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row4_col2{\n",
       "            background-color:  #e3f399;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row5_col1{\n",
       "            background-color:  #f57547;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row5_col2{\n",
       "            background-color:  #e5f49b;\n",
       "            color:  #000000;\n",
       "        }#T_9da6d_row5_col3{\n",
       "            background-color:  #d9ef8b;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_9da6d_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >content</th>        <th class=\"col_heading level0 col1\" >textblob</th>        <th class=\"col_heading level0 col2\" >textblob_bayes</th>        <th class=\"col_heading level0 col3\" >nltk</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9da6d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_9da6d_row0_col0\" class=\"data row0 col0\" >nothing I love more than my boss telling me I have to stay late on Friday</td>\n",
       "                        <td id=\"T_9da6d_row0_col1\" class=\"data row0 col1\" >0.233333</td>\n",
       "                        <td id=\"T_9da6d_row0_col2\" class=\"data row0 col2\" >-0.347051</td>\n",
       "                        <td id=\"T_9da6d_row0_col3\" class=\"data row0 col3\" >-0.521600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9da6d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_9da6d_row1_col0\" class=\"data row1 col0\" >thanks, I hate it! :)</td>\n",
       "                        <td id=\"T_9da6d_row1_col1\" class=\"data row1 col1\" >-0.100000</td>\n",
       "                        <td id=\"T_9da6d_row1_col2\" class=\"data row1 col2\" >0.242271</td>\n",
       "                        <td id=\"T_9da6d_row1_col3\" class=\"data row1 col3\" >0.359500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9da6d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_9da6d_row2_col0\" class=\"data row2 col0\" >lol real genius over here</td>\n",
       "                        <td id=\"T_9da6d_row2_col1\" class=\"data row2 col1\" >0.500000</td>\n",
       "                        <td id=\"T_9da6d_row2_col2\" class=\"data row2 col2\" >-0.714862</td>\n",
       "                        <td id=\"T_9da6d_row2_col3\" class=\"data row2 col3\" >0.421500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9da6d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_9da6d_row3_col0\" class=\"data row3 col0\" >hate love hate love love love hate hate HATE!!!!</td>\n",
       "                        <td id=\"T_9da6d_row3_col1\" class=\"data row3 col1\" >-0.244444</td>\n",
       "                        <td id=\"T_9da6d_row3_col2\" class=\"data row3 col2\" >0.134029</td>\n",
       "                        <td id=\"T_9da6d_row3_col3\" class=\"data row3 col3\" >0.633100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9da6d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_9da6d_row4_col0\" class=\"data row4 col0\" >haters gonna hate hate hate hate hate</td>\n",
       "                        <td id=\"T_9da6d_row4_col1\" class=\"data row4 col1\" >-0.800000</td>\n",
       "                        <td id=\"T_9da6d_row4_col2\" class=\"data row4 col2\" >0.865077</td>\n",
       "                        <td id=\"T_9da6d_row4_col3\" class=\"data row4 col3\" >-0.970900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9da6d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_9da6d_row5_col0\" class=\"data row5 col0\" >Can't believe I only have one more day in this beautiful paradise! I don't wanna leave! :(</td>\n",
       "                        <td id=\"T_9da6d_row5_col1\" class=\"data row5 col1\" >0.187500</td>\n",
       "                        <td id=\"T_9da6d_row5_col2\" class=\"data row5 col2\" >0.858606</td>\n",
       "                        <td id=\"T_9da6d_row5_col3\" class=\"data row5 col3\" >0.918000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x230387eb250>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = df.content.apply(get_scores)\n",
    "scores.style.background_gradient(cmap='RdYlGn', axis=None, low=-0.4, high=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: I showed the last quote to two actual humans and they themselves were confused about whether it was positive or negative. I meant it to be negative._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "**Sentiment analysis** is judging whether a piece of text has positive or negative emotion. We covered several tools for doing automatic sentiment analysis: **NLTK**, and two techniques inside of **TextBlob**.\n",
    "\n",
    "Each tool uses a different data to determine what is positive and negative, and while some use **humans** to flag things as positive or negative, others use a automatic **machine learning**.\n",
    "\n",
    "As a result of these differences, each tool can come up with very **different sentiment scores** for the same piece of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion topics\n",
    "\n",
    "The first questions are about whether an analyzer can be applied in situations other than where it was trained. Among other things, you'll want to think about whether the language it was trained on is similar to the language you're using it on.\n",
    "\n",
    "**Is it okay to use a sentiment analyzer built on product reviews to check the sentiment of tweets?** How about to check the sentiment of wine reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_It would probably be better to give some additional training to the sentiment analyzer that was gleaned specifically from Twitter posts. Internet/social media culture is very particular and involves many inside jokes based on the slightest nuances of language, spelling, capitalization, and punctuation (for example, \"ok\", \"ok.\" and \"OK!\" are completely different.) Wine review also has highly specialized vocabulary and so the sentiment analyzer would need additional training._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is it okay to use a sentiment analyzer trained on everything to check the sentiment of tweets?** How about to check the sentiment of wine reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_It looks like the NLTK analyzer, which was based on everything, was somewhat more accurate in analyzing the more complex sentiments, so it seems like it would work for both tweets and wine reviews. As noted above, it would probably be better to give it additional, specific training._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's say it's a night of political debates.** If I'm trying to report on whether people generally like or dislike what is happening throughout the debates, could I use these sorts of tools on tweets?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_My first issue is that Twitter does not represent public opinion AT ALL...but putting that aside, let's assume you put in a disclaimer that you only want to know what Twitter users think (or what opinion they are paid to express), not the general public. You could use the tool but in this case perhaps the tool trained on NYT op-eds would be better (if Fox news op-eds could be added too) as it might be more attuned to the nuances of political language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the incredibly vague word \"okay\" on purpose, as there are varying levels of comfort depending on your sitaution. Are you doing this for preliminary research? Are you publishing the results in a journal, in a newspaper, in a report at work, in a public policy recommendation?\n",
    "\n",
    "What if I tell you that the ideal of \"I'd only use a sentiment analysis tool trained exactly for my specific domain\" is both _rare and impractical?_ How comfortable do you feel with the output of sentiment analysis if that's the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_I feel like sentiment analysis may be helpful if it is combined with other tools that can back up its conclusions. For example, I would be more likely to trust an article that talked about public opinion in terms of sentiment analysis on social media, data from focus groups, AND public opinion surveys. If it relied ONLY on sentiment analysis, I would be suspicious. If someone used sentiment analysis on political speeches, I would question whether that analysis was more effective than simply employing the skills of an English major. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the last section, **these tools don't always agree with one another, which might be problematic.**\n",
    "\n",
    "* What might make them agree or disagree?\n",
    "* Do we think one is the \"best?\"\n",
    "* Can you think of any ways to test which one is the 'best' for our purposes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_To me, there was no clear winner. I might use NLTK for social media since it was designed for that purpose. If I was instead analyzing Yelp reviews, I might use one of the sentiment analyzers that were based on product reviews._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
